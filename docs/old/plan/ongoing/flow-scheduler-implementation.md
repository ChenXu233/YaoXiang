# FlowScheduler ä¾èµ–æ„ŸçŸ¥è°ƒåº¦å™¨å®ç°è®¡åˆ’

> **ä»»åŠ¡**ï¼šå…¨æ–°è®¾è®¡å¹¶å®ç°ä¾èµ–æ„ŸçŸ¥è°ƒåº¦å™¨ï¼Œæ”¯æŒ"é»˜è®¤æƒ°æ€§æ±‚å€¼ + spawn ç²¾ç»†æ§åˆ¶"æ¨¡å‹
> **æ—¥æœŸ**ï¼š2026-01-04
> **çŠ¶æ€**ï¼šè¿›è¡Œä¸­ï¼ˆè®¾è®¡å®Œæˆå¾…å®ç°ï¼‰
> **IO å¼•æ“**ï¼šä½¿ç”¨ libuv ä¿è¯å·¥ä¸šçº§å¯ç”¨æ€§

---

## å®é™…å®ç°çŠ¶æ€

### âœ… å·²å®Œæˆï¼ˆ2026-01-04ï¼‰

**è¯¦ç»†è®¾è®¡æ–‡æ¡£**ï¼š
- æ¶æ„è®¾è®¡å®Œæˆ
- æ ¸å¿ƒæ•°æ®ç»“æ„è®¾è®¡å®Œæˆï¼ˆDAGNodeã€ComputationDAGã€WorkStealer ç­‰ï¼‰
- FlowScheduler æ ¸å¿ƒé€»è¾‘è®¾è®¡å®Œæˆ
- libuv IO è°ƒåº¦å¼•æ“è®¾è®¡å®Œæˆ
- æµ‹è¯•è®¡åˆ’åˆ¶å®šå®Œæˆ
- éªŒæ”¶æ ‡å‡†å®šä¹‰å®Œæˆ

### ğŸ“‹ å·²é›†æˆç»„ä»¶

**ç°æœ‰ä»»åŠ¡ç³»ç»Ÿ**ï¼š
- Task/TaskId/TaskState å·²å®Œæˆ
- åŸºç¡€è°ƒåº¦å™¨æ¡†æ¶å·²å®Œæˆ
- ä½ç½®ï¼š`src/backends/runtime/task.rs`

**å‚è€ƒå®ç°æ–‡æ¡£**ï¼š
- RFC-001ï¼šå¹¶ä½œæ¨¡å‹ä¸é”™è¯¯å¤„ç†ç³»ç»Ÿ
- RFC-008ï¼šRuntime å¹¶å‘æ¨¡å‹ä¸è°ƒåº¦å™¨è„±è€¦è®¾è®¡
- RFC-003ï¼šç‰ˆæœ¬è§„åˆ’

### ğŸš§ å¾…å®ç°ï¼ˆv0.2ï¼‰

**ç¬¬ä¸€ä¼˜å…ˆçº§**ï¼š
1. DAG èŠ‚ç‚¹ä¸å›¾å®ç°
2. å·¥ä½œçªƒå–ç®—æ³•å®ç°
3. FlowScheduler æ ¸å¿ƒé€»è¾‘å®ç°

**ç¬¬äºŒä¼˜å…ˆçº§**ï¼š
4. libuv IO è°ƒåº¦å¼•æ“å®ç°
5. æƒ°æ€§æ±‚å€¼ç­–ç•¥å®ç°
6. spawn è¯­æ³•æ”¯æŒ

### ğŸ¯ ç›®æ ‡ç‰ˆæœ¬

- **v0.2**ï¼šFlowScheduler åŸºç¡€å®ç°
- **v0.3**ï¼šå®Œæ•´å¹¶å‘æ”¯æŒ
- **v0.5**ï¼šæ€§èƒ½ä¼˜åŒ–ä¸ç¨³å®šåŒ–

---

## æ ¸å¿ƒè®¾è®¡ç†å¿µ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     YaoXiang å¹¶ä½œæ¨¡å‹ - æ ¸å¿ƒåŸåˆ™                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. ã€é»˜è®¤æƒ°æ€§æ±‚å€¼ã€‘                                                         â”‚
â”‚     - æ‰€æœ‰å‡½æ•°é»˜è®¤æƒ°æ€§æ±‚å€¼ï¼ˆç±»ä¼¼ Haskellï¼‰                                   â”‚
â”‚     - æœ‰è¿”å›å€¼çš„å‡½æ•°ï¼šè¿”å›å€¼è¢«ä½¿ç”¨æ—¶æ‰æ±‚å€¼                                   â”‚
â”‚     - æ— è¿”å›å€¼å‡½æ•°ï¼šé€šè¿‡ç±»å‹æ ‡æ³¨ (@effect) ç¡®å®šæ‰§è¡Œæ—¶æœº                      â”‚
â”‚                                                                              â”‚
â”‚  2. ã€æ ¸å¿ƒæ•°é‡é…ç½®ã€‘                                                         â”‚
â”‚     - è„šæœ¬å¤´å£°æ˜ `// @cores: 4` è‡ªåŠ¨å¯ç”¨å¹¶è¡ŒåŒ–                              â”‚
â”‚     - è°ƒåº¦å™¨æ ¹æ®æ ¸å¿ƒæ•°è‡ªåŠ¨åˆ†é…å·¥ä½œçº¿ç¨‹                                       â”‚
â”‚                                                                              â”‚
â”‚  3. ã€spawn ç²¾ç»†æ§åˆ¶ã€‘                                                       â”‚
â”‚     - `spawn fn` - æ˜¾å¼æ ‡è®°ä¸ºå¼‚æ­¥å‡½æ•°                                        â”‚
â”‚     - `spawn { a, b }` - å¹¶è¡Œå—ï¼Œå—å†…è¡¨è¾¾å¼å¹¶è¡Œæ‰§è¡Œ                          â”‚
â”‚     - `spawn for x in xs` - æ•°æ®å¹¶è¡Œå¾ªç¯                                     â”‚
â”‚                                                                              â”‚
â”‚  4. ã€æ··åˆæ±‚å€¼æ¨¡å¼ã€‘                                                         â”‚
â”‚     - `@eager` - å¼ºåˆ¶æ€¥åˆ‡æ±‚å€¼                                               â”‚
â”‚     - `@lazy` - ä¿æŒæƒ°æ€§ï¼ˆé»˜è®¤ï¼‰                                            â”‚
â”‚     - `@force` - æ˜¾å¼è§¦å‘æ±‚å€¼                                               â”‚
â”‚     - è‡ªåŠ¨æ£€æµ‹æœ€ä½³æ±‚å€¼ç­–ç•¥                                                   â”‚
â”‚                                                                              â”‚
â”‚  5. ã€å·¥ä¸šçº§ IO è°ƒåº¦ã€‘                                                       â”‚
â”‚     - ä½¿ç”¨ libuv ä½œä¸ºåº•å±‚ IO å¼•æ“                                            â”‚
â”‚     - é«˜æ€§èƒ½å¼‚æ­¥ IOï¼ˆepoll/kqueue/IOCPï¼‰                                     â”‚
â”‚     - æ–‡ä»¶ç³»ç»Ÿæ“ä½œã€TCP/UDP ç½‘ç»œæ“ä½œ                                         â”‚
â”‚     - å®šæ—¶å™¨ã€ä¿¡å·å¤„ç†                                                       â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ä¸€ã€æ¶æ„æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          FlowScheduler æ¶æ„å›¾                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   DAG Node       â”‚   â”‚   ComputationDAG â”‚   â”‚   FlowScheduler  â”‚        â”‚
â”‚  â”‚   (èŠ‚ç‚¹)         â”‚   â”‚   (è®¡ç®—å›¾)       â”‚   â”‚   (è°ƒåº¦å™¨)        â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚           â”‚                      â”‚                      â”‚                   â”‚
â”‚           â”‚                      â”‚                      â”‚                   â”‚
â”‚           â–¼                      â–¼                      â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      è¿è¡Œæ—¶æ ¸å¿ƒç»„ä»¶                                    â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚ WorkStealer â”‚  â”‚ TaskQueue   â”‚  â”‚ AsyncValue  â”‚  â”‚ BlockingPoolâ”‚ â”‚   â”‚
â”‚  â”‚  â”‚ (å·¥ä½œçªƒå–)  â”‚  â”‚ (ä»»åŠ¡é˜Ÿåˆ—)  â”‚  â”‚ (å¼‚æ­¥å€¼)    â”‚  â”‚ (é˜»å¡æ± )    â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    libuv IO è°ƒåº¦å¼•æ“ (å·¥ä¸šçº§)                         â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚   TCP/UDP   â”‚  â”‚    File     â”‚  â”‚   Timers    â”‚  â”‚   Signals   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚   Network   â”‚  â”‚   System    â”‚  â”‚  & Sleep    â”‚  â”‚  Handling   â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚   Poll      â”‚  â”‚   Check     â”‚  â”‚   Prepare   â”‚  â”‚   Idle      â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  (IO å¤šè·¯)  â”‚  â”‚  (æ£€æŸ¥)     â”‚  â”‚  (å‡†å¤‡)     â”‚  â”‚  (ç©ºé—²)     â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  æ”¯æŒå¹³å°ï¼šLinux (epoll), macOS (kqueue), Windows (IOCP)            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äºŒã€æ¨¡å—åˆ’åˆ†ä¸ä¾èµ–å…³ç³»

### 2.1 æ–°å¢æ–‡ä»¶ç»“æ„

```
src/runtime/
â”œâ”€â”€ mod.rs              # è¿è¡Œæ—¶æ¨¡å—å…¥å£ï¼ˆä¿®æ”¹ï¼‰
â”œâ”€â”€ scheduler/
â”‚   â”œâ”€â”€ mod.rs          # è°ƒåº¦å™¨æ¨¡å—ï¼ˆå…¨æ–°è®¾è®¡ï¼‰
â”‚   â”œâ”€â”€ task.rs         # ä»»åŠ¡å®šä¹‰
â”‚   â”œâ”€â”€ work_stealer.rs # å·¥ä½œçªƒå–å™¨
â”‚   â”œâ”€â”€ queue.rs        # ä»»åŠ¡é˜Ÿåˆ—
â”‚   â””â”€â”€ tests/          # è°ƒåº¦å™¨æµ‹è¯•
â”‚       â””â”€â”€ mod.rs
â”œâ”€â”€ dag/
â”‚   â”œâ”€â”€ mod.rs          # DAG æ¨¡å—å…¥å£
â”‚   â”œâ”€â”€ node_id.rs      # èŠ‚ç‚¹ ID å’Œç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ node.rs         # DAG èŠ‚ç‚¹
â”‚   â”œâ”€â”€ graph.rs        # è®¡ç®—å›¾
â”‚   â””â”€â”€ tests/          # DAG æµ‹è¯•
â”‚       â””â”€â”€ mod.rs
â”œâ”€â”€ async_value/
â”‚   â”œâ”€â”€ mod.rs          # Async[T] æ¨¡å—å…¥å£
â”‚   â”œâ”€â”€ async_value.rs  # å¼‚æ­¥å€¼ç±»å‹
â”‚   â”œâ”€â”€ future_wrapper.rs # Future åŒ…è£…å™¨
â”‚   â””â”€â”€ tests/          # Async æµ‹è¯•
â”‚       â””â”€â”€ mod.rs
â”œâ”€â”€ blocking_pool/
â”‚   â”œâ”€â”€ mod.rs          # é˜»å¡çº¿ç¨‹æ± 
â”‚   â””â”€â”€ tests/          # é˜»å¡æ± æµ‹è¯•
â”‚       â””â”€â”€ mod.rs
â””â”€â”€ io/
    â”œâ”€â”€ mod.rs          # libuv IO æ¨¡å—å…¥å£
    â”œâ”€â”€ uv_loop.rs      # libuv äº‹ä»¶å¾ªç¯å°è£…
    â”œâ”€â”€ uv_tcp.rs       # TCP/UDP ç½‘ç»œæ“ä½œ
    â”œâ”€â”€ uv_fs.rs        # æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
    â”œâ”€â”€ uv_timer.rs     # å®šæ—¶å™¨
    â””â”€â”€ tests/          # IO æµ‹è¯•
        â””â”€â”€ mod.rs
```

### 2.2 å…¼å®¹æ€§è®¾è®¡

```rust
// å‘åå…¼å®¹ï¼šä¿ç•™æ—§ç‰ˆ Scheduler API
pub mod scheduler {
    use super::flow::FlowScheduler;

    // ç®€å•ä»»åŠ¡è°ƒåº¦çš„å…¼å®¹æ¥å£
    #[deprecated(since = "0.3.0", note = "è¯·ä½¿ç”¨ FlowScheduler")]
    pub struct Scheduler(FlowScheduler);

    impl Scheduler {
        #[deprecated]
        pub fn spawn(&self, task: Arc<Task>) {
            // å§”æ‰˜ç»™ FlowSchedulerï¼Œè‡ªåŠ¨åˆ›å»ºæ— ä¾èµ–ä»»åŠ¡
            self.0.spawn_untracked(task);
        }
    }
}
```

---

## ä¸‰ã€æ ¸å¿ƒæ•°æ®ç»“æ„è®¾è®¡

### 3.1 èŠ‚ç‚¹ IDï¼ˆè‡ªå¢ ID ç”Ÿæˆå™¨ï¼‰

```rust
// src/runtime/dag/node.rs

/// èŠ‚ç‚¹ IDï¼Œä½¿ç”¨è‡ªå¢æ•´æ•°
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub struct NodeId(usize);

impl NodeId {
    /// åˆ›å»ºæ–°èŠ‚ç‚¹ IDï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰
    pub(crate) fn new(inner: usize) -> Self {
        Self(inner)
    }

    /// è·å–å†…éƒ¨å€¼
    pub fn inner(&self) -> usize {
        self.0
    }
}

/// èŠ‚ç‚¹ ID ç”Ÿæˆå™¨
#[derive(Debug, Default)]
pub struct NodeIdGenerator(usize);

impl NodeIdGenerator {
    /// ç”Ÿæˆæ–°çš„èŠ‚ç‚¹ ID
    pub fn next(&mut self) -> NodeId {
        let id = self.0;
        self.0 += 1;
        NodeId(id)
    }
}
```

### 3.2 DAG èŠ‚ç‚¹çŠ¶æ€

```rust
// src/runtime/dag/node.rs

/// èŠ‚ç‚¹çŠ¶æ€
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum NodeState {
    /// æœªå°±ç»ªï¼ˆæœ‰å¾…å®Œæˆçš„ä¾èµ–ï¼‰
    Pending,
    /// å·²è°ƒåº¦ï¼ˆç­‰å¾…æ‰§è¡Œï¼‰
    Scheduled,
    /// æ‰§è¡Œä¸­
    Running,
    /// å·²å®Œæˆ
    Completed,
    /// å¤±è´¥
    Failed,
    /// å·²å–æ¶ˆ
    Cancelled,
}

/// èŠ‚ç‚¹ç±»å‹ï¼ˆä½“ç°"é»˜è®¤æƒ°æ€§ + spawn ç²¾ç»†æ§åˆ¶"ï¼‰
#[derive(Debug, Clone)]
pub enum NodeKind {
    /// æƒ°æ€§è®¡ç®—èŠ‚ç‚¹ï¼ˆé»˜è®¤ï¼‰- å»¶è¿Ÿåˆ°éœ€è¦æ—¶æ‰æ‰§è¡Œ
    LazyCompute,
    /// æ€¥åˆ‡è®¡ç®—èŠ‚ç‚¹ï¼ˆ@eagerï¼‰- ç«‹å³æ‰§è¡Œ
    EagerCompute,
    /// å¼‚æ­¥è®¡ç®—èŠ‚ç‚¹ï¼ˆspawn fnï¼‰- è¿”å› Async[T]
    AsyncCompute,
    /// å¹¶è¡Œå—èŠ‚ç‚¹ï¼ˆspawn {}ï¼‰- å—å†…å¹¶è¡Œæ‰§è¡Œ
    ParallelBlock {
        /// å—å†…è¡¨è¾¾å¼
        exprs: Vec<Expr>,
        /// å±éšœåŒæ­¥
        barrier: bool,
    },
    /// æ•°æ®å¹¶è¡ŒèŠ‚ç‚¹ï¼ˆspawn forï¼‰
    DataParallel {
        /// è¿­ä»£å˜é‡å
        var: String,
        /// è¿­ä»£å™¨è¡¨è¾¾å¼
        iter: Expr,
        /// å¾ªç¯ä½“
        body: Expr,
    },
    /// å‰¯ä½œç”¨èŠ‚ç‚¹ï¼ˆæ— è¿”å›å€¼å‡½æ•°ï¼‰- @effect æ ‡è®°
    Effect {
        /// æ‰§è¡Œå‡½æ•°
        func: Expr,
        /// æ‰§è¡Œæ—¶æœºï¼šImmediate/Deferred
        timing: EffectTiming,
    },
    /// I/O æ“ä½œèŠ‚ç‚¹
    IO,
    /// é˜»å¡æ“ä½œèŠ‚ç‚¹ï¼ˆ@blockingï¼‰
    Blocking,
}

/// å‰¯ä½œç”¨æ‰§è¡Œæ—¶æœº
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum EffectTiming {
    /// ç«‹å³æ‰§è¡Œï¼ˆé»˜è®¤ï¼‰
    Immediate,
    /// å»¶è¿Ÿåˆ°ç¨‹åºé€€å‡ºå‰
    Deferred,
    /// å»¶è¿Ÿåˆ°ä½œç”¨åŸŸç»“æŸæ—¶
    ScopeEnd,
}

/// èŠ‚ç‚¹æ‰§è¡Œç»“æœ
#[derive(Debug)]
pub enum NodeResult {
    /// æˆåŠŸå®Œæˆ
    Success(Value),
    /// é”™è¯¯
    Error(DynError),
    /// å–æ¶ˆ
    Cancelled,
}
```

### 3.3 DAG èŠ‚ç‚¹

```rust
// src/runtime/dag/node.rs

/// DAG èŠ‚ç‚¹
#[derive(Debug)]
pub struct DAGNode {
    /// èŠ‚ç‚¹ ID
    id: NodeId,
    /// èŠ‚ç‚¹ç±»å‹
    kind: NodeKind,
    /// èŠ‚ç‚¹çŠ¶æ€
    state: AtomicU8, // NodeState çš„åŸå­ç‰ˆæœ¬
    /// ä¾èµ–çš„çˆ¶èŠ‚ç‚¹ ID
    parents: Vec<NodeId>,
    /// ä¾èµ–çš„å­èŠ‚ç‚¹ ID
    children: Vec<NodeId>,
    /// æœªå®Œæˆçš„çˆ¶èŠ‚ç‚¹è®¡æ•°ï¼ˆç”¨äºå°±ç»ªåˆ¤æ–­ï¼‰
    pending_parents: AtomicUsize,
    /// æ‰§è¡Œç»“æœï¼ˆOnceCell ä¿è¯åªå†™å…¥ä¸€æ¬¡ï¼‰
    result: OnceCell<NodeResult>,
    /// ä»»åŠ¡æ‰§è¡Œå™¨ï¼ˆè¿è¡Œæ—¶å¡«å……ï¼‰
    executor: OnceCell<Arc<dyn Fn() + Send + Sync>>,
    /// å…ƒæ•°æ®
    metadata: NodeMetadata,
}

/// èŠ‚ç‚¹å…ƒæ•°æ®
#[derive(Debug, Clone, Default)]
pub struct NodeMetadata {
    /// èŠ‚ç‚¹åç§°ï¼ˆè°ƒè¯•ç”¨ï¼‰
    name: String,
    /// ä¼˜å…ˆçº§
    priority: TaskPriority,
    /// åˆ›å»ºæ—¶é—´
    created_at: std::time::Instant,
    /// è°ƒåº¦å»¶è¿Ÿç»Ÿè®¡
    schedule_delay: Duration,
    /// æ‰§è¡Œæ—¶é—´ç»Ÿè®¡
    exec_duration: Duration,
}

impl DAGNode {
    /// åˆ›å»ºæ–°èŠ‚ç‚¹
    pub fn new(id: NodeId, kind: NodeKind) -> Self {
        let pending_parents = AtomicUsize::new(0);
        Self {
            id,
            kind,
            state: AtomicU8::new(NodeState::Pending as u8),
            parents: Vec::new(),
            children: Vec::new(),
            pending_parents,
            result: OnceCell::new(),
            executor: OnceCell::new(),
            metadata: NodeMetadata::default(),
        }
    }

    /// æ·»åŠ çˆ¶èŠ‚ç‚¹ä¾èµ–
    pub fn add_parent(&mut self, parent_id: NodeId) {
        self.parents.push(parent_id);
        self.pending_parents.fetch_add(1, Ordering::SeqCst);
    }

    /// æ·»åŠ å­èŠ‚ç‚¹ä¾èµ–
    pub fn add_child(&mut self, child_id: NodeId) {
        self.children.push(child_id);
    }

    /// æ£€æŸ¥æ˜¯å¦å°±ç»ªï¼ˆæ‰€æœ‰çˆ¶èŠ‚ç‚¹å·²å®Œæˆï¼‰
    pub fn is_ready(&self) -> bool {
        self.pending_parents.load(Ordering::SeqCst) == 0
    }

    /// æ ‡è®°ä¸€ä¸ªçˆ¶èŠ‚ç‚¹å®Œæˆ
    pub fn parent_completed(&self) {
        self.pending_parents.fetch_sub(1, Ordering::SeqCst);
    }

    /// åŸå­åœ°è®¾ç½®çŠ¶æ€
    pub fn set_state(&self, state: NodeState) {
        self.state.store(state as u8, Ordering::SeqCst);
    }

    /// åŸå­åœ°è·å–çŠ¶æ€
    pub fn state(&self) -> NodeState {
        NodeState::from_u8(self.state.load(Ordering::SeqCst))
    }
}
```

### 3.4 è®¡ç®—å›¾ (DAG)

```rust
// src/runtime/dag/graph.rs

/// è®¡ç®—å›¾
#[derive(Debug)]
pub struct ComputationDAG {
    /// æ‰€æœ‰èŠ‚ç‚¹
    nodes: DashMap<NodeId, Arc<DAGNode>>,
    /// æ‹“æ‰‘æ’åºçš„å°±ç»ªé˜Ÿåˆ—
    ready_queue: Arc<Mutex<VecDeque<NodeId>>>,
    /// è¿è¡Œä¸­èŠ‚ç‚¹é›†åˆ
    running: Arc<Mutex<HashSet<NodeId>>>,
    /// å·²å®ŒæˆèŠ‚ç‚¹é›†åˆ
    completed: Arc<Mutex<HashSet<NodeId>>},
    /// èŠ‚ç‚¹ ID ç”Ÿæˆå™¨
    id_generator: Mutex<NodeIdGenerator>,
    /// å¹¶è¡Œè¾¹ç•Œï¼ˆspawn {} æ ‡è®°çš„åŒºåŸŸï¼‰
    parallel_boundaries: DashMap<BoundaryId, ParallelBoundary>,
    /// ç»Ÿè®¡ä¿¡æ¯
    stats: DAGStats,
}

/// ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Default)]
pub struct DAGStats {
    /// æ€»èŠ‚ç‚¹æ•°
    total_nodes: AtomicUsize,
    /// å¹¶è¡Œæ‰§è¡Œçš„èŠ‚ç‚¹å¯¹æ•°
    parallel_pairs: AtomicUsize,
    /// æœ€å¤§å¹¶è¡Œåº¦
    max_parallelism: AtomicUsize,
    /// æ€»æ‰§è¡Œæ—¶é—´
    total_exec_time: AtomicU64,
}

impl ComputationDAG {
    /// åˆ›å»ºæ–°è®¡ç®—å›¾
    pub fn new() -> Self {
        Self {
            nodes: DashMap::new(),
            ready_queue: Arc::new(Mutex::new(VecDeque::new())),
            running: Arc::new(Mutex::new(HashSet::new())),
            completed: Arc::new(Mutex::new(HashSet::new())),
            id_generator: Mutex::new(NodeIdGenerator::default()),
            parallel_boundaries: DashMap::new(),
            stats: DAGStats::default(),
        }
    }

    /// æ·»åŠ èŠ‚ç‚¹
    pub fn add_node(&self, kind: NodeKind, dependencies: &[NodeId]) -> NodeId {
        let mut id_generator = self.id_generator.lock().unwrap();
        let node_id = id_generator.next();

        let node = Arc::new(DAGNode::new(node_id, kind));

        // å»ºç«‹ä¾èµ–å…³ç³»
        for &dep_id in dependencies {
            if let Some(dep_node) = self.nodes.get(&dep_id) {
                // æ·»åŠ å½“å‰èŠ‚ç‚¹ä¸º dep_node çš„å­èŠ‚ç‚¹
                // æ³¨æ„ï¼šéœ€è¦å…‹éš† Arc
                let mut dep_node_mut = dep_node.value().clone();
                dep_node_mut.add_child(node_id);
            }
            // å½“å‰èŠ‚ç‚¹ä¾èµ– dep_id
            let mut node_mut = node.clone();
            node_mut.add_parent(dep_id);
        }

        // æ£€æŸ¥æ˜¯å¦å°±ç»ª
        if node.is_ready() {
            self.ready_queue.lock().unwrap().push_back(node_id);
        }

        self.nodes.insert(node_id, node);
        self.stats.total_nodes.fetch_add(1, Ordering::SeqCst);

        node_id
    }

    /// è·å–å°±ç»ªèŠ‚ç‚¹
    pub fn pop_ready(&self) -> Option<NodeId> {
        self.ready_queue.lock().unwrap().pop_front()
    }

    /// èŠ‚ç‚¹å®Œæˆï¼Œé€šçŸ¥å­èŠ‚ç‚¹
    pub fn node_completed(&self, node_id: NodeId) {
        // æ ‡è®°èŠ‚ç‚¹ä¸ºå®Œæˆ
        self.completed.lock().unwrap().insert(node_id);

        // é€šçŸ¥æ‰€æœ‰å­èŠ‚ç‚¹
        if let Some(node) = self.nodes.get(&node_id) {
            for child_id in node.children.clone() {
                if let Some(child) = self.nodes.get(&child_id) {
                    child.parent_completed();
                    // å¦‚æœå­èŠ‚ç‚¹å°±ç»ªï¼ŒåŠ å…¥å°±ç»ªé˜Ÿåˆ—
                    if child.is_ready() {
                        self.ready_queue.lock().unwrap().push_back(child_id);
                    }
                }
            }
        }
    }
}
```

### 3.5 å·¥ä½œçªƒå–å™¨

```rust
// src/runtime/scheduler/work_stealer.rs

/// å·¥ä½œçªƒå–å™¨
#[derive(Debug)]
pub struct WorkStealer {
    /// æ‰€æœ‰å·¥ä½œçº¿ç¨‹çš„æœ¬åœ°é˜Ÿåˆ—å¼•ç”¨
    queues: Arc<RwLock<Vec<Arc<TaskQueue>>>>,
    /// å½“å‰å·¥ä½œçº¿ç¨‹ ID
    current_worker: AtomicUsize,
    /// çªƒå–ç­–ç•¥
    strategy: StealStrategy,
}

/// çªƒå–ç­–ç•¥
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum StealStrategy {
    /// ä»é˜Ÿåˆ—å°¾éƒ¨çªƒå–ï¼ˆå‡å°‘å†²çªï¼‰
    Random,
    /// ä»é˜Ÿåˆ—å¤´éƒ¨çªƒå–ï¼ˆå…ˆè¿›å…ˆå‡ºï¼‰
    FIFO,
    /// åŒç«¯çªƒå–
    Deque,
}

impl WorkStealer {
    /// åˆ›å»ºå·¥ä½œçªƒå–å™¨
    pub fn new(num_workers: usize) -> Self {
        let mut queues = Vec::with_capacity(num_workers);
        for _ in 0..num_workers {
            queues.push(Arc::new(TaskQueue::new()));
        }

        Self {
            queues: Arc::new(RwLock::new(queues)),
            current_worker: AtomicUsize::new(0),
            strategy: StealStrategy::Random,
        }
    }

    /// æ³¨å†Œå·¥ä½œçº¿ç¨‹
    pub fn register_worker(&self, worker_id: usize) {
        self.current_worker.store(worker_id, Ordering::SeqCst);
    }

    /// å°è¯•çªƒå–ä»»åŠ¡
    pub fn steal(&self, victim_id: usize) -> Option<Arc<Task>> {
        let queues = self.queues.read().unwrap();
        if victim_id >= queues.len() {
            return None;
        }

        let queue = &queues[victim_id];
        queue.pop_back() // ä»å°¾éƒ¨çªƒå–ï¼Œå‡å°‘ä¸ victim çš„ç«äº‰
    }

    /// ä»éšæœºå·¥ä½œçº¿ç¨‹çªƒå–
    pub fn steal_random(&self) -> Option<Arc<Task>> {
        let queues = self.queues.read().unwrap();
        if queues.is_empty() {
            return None;
        }

        let num_workers = queues.len();
        let mut attempts = 0;
        let mut rng = rand::thread_rng();

        while attempts < num_workers {
            let victim_id = rng.gen_range(0..num_workers);
            if victim_id == self.current_worker.load(Ordering::SeqCst) {
                attempts += 1;
                continue;
            }

            if let Some(task) = self.steal(victim_id) {
                return Some(task);
            }
            attempts += 1;
        }

        None
    }

    /// ä»æ‰€æœ‰é˜Ÿåˆ—çªƒå–
    pub fn steal_all(&self) -> Vec<Arc<Task>> {
        let mut stolen = Vec::new();
        let queues = self.queues.read().unwrap();

        for (i, queue) in queues.iter().enumerate() {
            if i == self.current_worker.load(Ordering::SeqCst) {
                continue; // è·³è¿‡è‡ªå·±çš„é˜Ÿåˆ—
            }

            while let Some(task) = queue.pop_back() {
                stolen.push(task);
            }
        }

        stolen
    }
}
```

### 3.6 ä»»åŠ¡é˜Ÿåˆ—

```rust
// src/runtime/scheduler/queue.rs

/// ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæ”¯æŒå¤šç”Ÿäº§è€…å¤šæ¶ˆè´¹è€…ï¼‰
#[derive(Debug)]
pub struct TaskQueue {
    /// å†…éƒ¨ dequeï¼ˆä½¿ç”¨ Mutex ä¿è¯çº¿ç¨‹å®‰å…¨ï¼‰
    inner: Arc<Mutex<VecDeque<Arc<Task>>>>,
    /// ä¼˜å…ˆçº§ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
    priority_indices: HashMap<TaskPriority, VecDeque<usize>>,
}

impl TaskQueue {
    /// åˆ›å»ºæ–°ä»»åŠ¡é˜Ÿåˆ—
    pub fn new() -> Self {
        Self {
            inner: Arc::new(Mutex::new(VecDeque::new())),
            priority_indices: HashMap::new(),
        }
    }

    /// å‹å…¥ä»»åŠ¡ï¼ˆé˜Ÿå°¾ï¼‰
    pub fn push(&self, task: Arc<Task>) {
        let mut inner = self.inner.lock().unwrap();
        inner.push_back(task);
    }

    /// å‹å…¥ä»»åŠ¡ï¼ˆé˜Ÿå¤´ï¼Œé«˜ä¼˜å…ˆçº§ï¼‰
    pub fn push_front(&self, task: Arc<Task>) {
        let mut inner = self.inner.lock().unwrap();
        inner.push_front(task);
    }

    /// å¼¹å‡ºä»»åŠ¡ï¼ˆé˜Ÿå¤´ï¼‰
    pub fn pop_front(&self) -> Option<Arc<Task>> {
        self.inner.lock().unwrap().pop_front()
    }

    /// å¼¹å‡ºä»»åŠ¡ï¼ˆé˜Ÿå°¾ï¼Œç”¨äºçªƒå–ï¼‰
    pub fn pop_back(&self) -> Option<Arc<Task>> {
        self.inner.lock().unwrap().pop_back()
    }

    /// è·å–é˜Ÿåˆ—é•¿åº¦
    pub fn len(&self) -> usize {
        self.inner.lock().unwrap().len()
    }

    /// æ£€æŸ¥æ˜¯å¦ä¸ºç©º
    pub fn is_empty(&self) -> bool {
        self.inner.lock().unwrap().is_empty()
    }
}
```

### 3.7 FlowScheduler æ ¸å¿ƒ

```rust
// src/runtime/scheduler/mod.rs

/// ä¾èµ–æ„ŸçŸ¥è°ƒåº¦å™¨ï¼ˆFlowSchedulerï¼‰
///
/// æ ¸å¿ƒç‰¹æ€§ï¼š
/// 1. DAG ä¾èµ–æ„ŸçŸ¥è°ƒåº¦
/// 2. å·¥ä½œçªƒå–è´Ÿè½½å‡è¡¡
/// 3. æ”¯æŒå¹¶è¡Œå— (spawn {})
/// 4. æ”¯æŒæ•°æ®å¹¶è¡Œ (spawn for)
/// 5. é˜»å¡æ“ä½œéš”ç¦»
#[derive(Debug)]
pub struct FlowScheduler {
    /// é…ç½®
    config: SchedulerConfig,
    /// è®¡ç®—å›¾
    dag: Arc<ComputationDAG>,
    /// å·¥ä½œçªƒå–å™¨
    work_stealer: WorkStealer,
    /// æ‰€æœ‰æœ¬åœ°é˜Ÿåˆ—ï¼ˆç”¨äºçªƒå–ï¼‰
    local_queues: Arc<RwLock<Vec<Arc<TaskQueue>>>>,
    /// å·¥ä½œçº¿ç¨‹
    workers: Vec<JoinHandle<()>>,
    /// è¿è¡ŒçŠ¶æ€
    running: Arc<AtomicBool>,
    /// ä»»åŠ¡å®Œæˆé€šçŸ¥
    completion_notifier: Arc<Notify>,
    /// é˜»å¡çº¿ç¨‹æ± 
    blocking_pool: BlockingThreadPool,
    /// ç»Ÿè®¡ä¿¡æ¯
    stats: SchedulerStats,
}

/// è°ƒåº¦å™¨ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Default)]
pub struct SchedulerStats {
    /// å·²å®Œæˆä»»åŠ¡æ•°
    completed_tasks: AtomicUsize,
    /// è¢«çªƒå–çš„ä»»åŠ¡æ•°
    stolen_tasks: AtomicUsize,
    /// çªƒå–æˆåŠŸæ¬¡æ•°
    steal_successes: AtomicUsize,
    /// çªƒå–å¤±è´¥æ¬¡æ•°
    steal_failures: AtomicUsize,
    /// æ€»è°ƒåº¦å»¶è¿Ÿ
    total_schedule_delay: AtomicU64,
    /// æœ€å¤§å¹¶è¡Œåº¦
    peak_parallelism: AtomicUsize,
}

impl FlowScheduler {
    /// åˆ›å»ºæ–°è°ƒåº¦å™¨
    pub fn new() -> Self {
        Self::with_config(SchedulerConfig::default())
    }

    /// ä½¿ç”¨é…ç½®åˆ›å»ºè°ƒåº¦å™¨
    pub fn with_config(config: SchedulerConfig) -> Self {
        let num_workers = config.num_workers;
        let running = Arc::new(AtomicBool::new(true));
        let completion_notifier = Arc::new(Notify());

        let work_stealer = WorkStealer::new(num_workers);
        let local_queues = Arc::new(RwLock::new(
            (0..num_workers)
                .map(|_| Arc::new(TaskQueue::new()))
                .collect(),
        ));

        let dag = Arc::new(ComputationDAG::new());
        let blocking_pool = BlockingThreadPool::new(config.blocking_pool_size);

        let workers = Self::spawn_workers(
            num_workers,
            &running,
            &work_stealer,
            &local_queues,
            &dag,
            &completion_notifier,
        );

        Self {
            config,
            dag,
            work_stealer,
            local_queues,
            workers,
            running,
            completion_notifier,
            blocking_pool,
            stats: SchedulerStats::default(),
        }
    }

    /// åˆ›å»ºå·¥ä½œçº¿ç¨‹
    fn spawn_workers(
        num_workers: usize,
        running: &Arc<AtomicBool>,
        work_stealer: &WorkStealer,
        local_queues: &Arc<RwLock<Vec<Arc<TaskQueue>>>>,
        dag: &Arc<ComputationDAG>,
        completion_notifier: &Arc<Notify>,
    ) -> Vec<JoinHandle<()>> {
        let mut workers = Vec::with_capacity(num_workers);

        for worker_id in 0..num_workers {
            let running = running.clone();
            let work_stealer = work_stealer.clone();
            let local_queues = local_queues.clone();
            let dag = dag.clone();
            let completion_notifier = completion_notifier.clone();

            let worker = thread::spawn(move || {
                Self::worker_loop(
                    worker_id,
                    &running,
                    &work_stealer,
                    &local_queues,
                    &dag,
                    &completion_notifier,
                );
            });

            workers.push(worker);
        }

        workers
    }

    /// å·¥ä½œçº¿ç¨‹ä¸»å¾ªç¯
    fn worker_loop(
        worker_id: usize,
        running: &Arc<AtomicBool>,
        work_stealer: &WorkStealer,
        local_queues: &Arc<RwLock<Vec<Arc<TaskQueue>>>>,
        dag: &Arc<ComputationDAG>,
        completion_notifier: &Arc<Notify>,
    ) {
        work_stealer.register_worker(worker_id);

        while running.load(Ordering::SeqCst) {
            // 1. å°è¯•ä»æœ¬åœ°é˜Ÿåˆ—è·å–
            if let Some(task) = Self::pop_local(worker_id, local_queues) {
                Self::execute_task(worker_id, task, dag, completion_notifier);
                continue;
            }

            // 2. å°è¯•ä»å°±ç»ªé˜Ÿåˆ—è·å–ï¼ˆDAG æ„ŸçŸ¥ï¼‰
            if let Some(node_id) = dag.pop_ready() {
                Self::execute_node(worker_id, node_id, dag, completion_notifier);
                continue;
            }

            // 3. å°è¯•çªƒå–
            if let Some(task) = work_stealer.steal_random() {
                Self::execute_task(worker_id, task, dag, completion_notifier);
                continue;
            }

            // 4. æ— ä»»åŠ¡å¯æ‰§è¡Œï¼Œç­‰å¾…
            completion_notifier.notified().await;
        }
    }

    /// ä»æœ¬åœ°é˜Ÿåˆ—å¼¹å‡ºä»»åŠ¡
    fn pop_local(
        worker_id: usize,
        local_queues: &Arc<RwLock<Vec<Arc<TaskQueue>>>>,
    ) -> Option<Arc<Task>> {
        let queues = local_queues.read().unwrap();
        if worker_id < queues.len() {
            queues[worker_id].pop_front()
        } else {
            None
        }
    }

    /// æ‰§è¡Œä»»åŠ¡
    fn execute_task(
        worker_id: usize,
        task: Arc<Task>,
        dag: &Arc<ComputationDAG>,
        completion_notifier: &Arc<Notify>,
    ) {
        task.set_state(TaskState::Running);

        // æ‰§è¡Œä»»åŠ¡é€»è¾‘
        // TODO: è°ƒç”¨ä»»åŠ¡çš„å®é™…æ‰§è¡Œå‡½æ•°

        task.set_state(TaskState::Finished);
        completion_notifier.notify_one();
    }

    /// æ‰§è¡ŒèŠ‚ç‚¹
    fn execute_node(
        worker_id: usize,
        node_id: NodeId,
        dag: &Arc<ComputationDAG>,
        completion_notifier: &Arc<Notify>,
    ) {
        if let Some(node) = dag.nodes.get(&node_id) {
            node.set_state(NodeState::Running);

            // æ‰§è¡ŒèŠ‚ç‚¹é€»è¾‘
            // TODO: è°ƒç”¨èŠ‚ç‚¹çš„æ‰§è¡Œå™¨

            node.set_state(NodeState::Completed);
            dag.node_completed(node_id);
            completion_notifier.notify_one();
        }
    }

    /// æäº¤æ— ä¾èµ–ä»»åŠ¡ï¼ˆå…¼å®¹æ—§ APIï¼‰
    pub fn spawn_untracked(&self, task: Arc<Task>) {
        let queues = self.local_queues.read().unwrap();
        let worker_id = rand::thread_rng().gen_range(0..queues.len());
        queues[worker_id].push(task);
    }

    /// æäº¤å¸¦ä¾èµ–çš„ä»»åŠ¡
    pub fn spawn_with_deps(&self, task: Arc<Task>, dependencies: &[NodeId]) -> NodeId {
        self.dag.add_node(NodeKind::Compute, dependencies)
    }

    /// å…³é—­è°ƒåº¦å™¨
    pub fn shutdown(&mut self) {
        self.running.store(false, Ordering::SeqCst);

        // å”¤é†’æ‰€æœ‰ç­‰å¾…çš„å·¥ä½œçº¿ç¨‹
        for _ in 0..self.workers.len() {
            self.completion_notifier.notify_one();
        }

        // ç­‰å¾…å·¥ä½œçº¿ç¨‹ç»“æŸ
        for worker in self.workers.drain(..) {
            worker.join().unwrap();
        }

        // å…³é—­é˜»å¡çº¿ç¨‹æ± 
        self.blocking_pool.shutdown();
    }
}
```

### 3.8 Async[T] å¼‚æ­¥å€¼ç±»å‹

```rust
// src/runtime/async_value/async_value.rs

/// Async[T] - æƒ°æ€§ä»£ç†ç±»å‹
///
/// å®ç°"é›¶ä¼ æŸ“æ€§"ï¼š
/// 1. Async<T> æ˜¯ T çš„å­ç±»å‹
/// 2. åœ¨éœ€è¦ T çš„ä¸Šä¸‹æ–‡ä¸­è‡ªåŠ¨è§£åŒ…
/// 3. å†…éƒ¨å®é™…å­˜å‚¨ Result<T, E> ä»¥æ”¯æŒé”™è¯¯ä¼ æ’­
#[repr(transparent)]
pub struct Async<T: Send + 'static> {
    inner: Arc<AsyncInner<T>>,
}

/// å¼‚æ­¥å€¼å†…éƒ¨å®ç°
struct AsyncInner<T: Send + 'static> {
    /// å®é™…çš„ Future
    future: Mutex<Option<Pin<Box<dyn Future<Output = Result<T, DynError>> + Send + 'static>>>>,
    /// ä»»åŠ¡æ‰§è¡Œå™¨
    executor: TaskExecutor,
    /// çŠ¶æ€
    state: AtomicU8,
    /// ç»“æœç¼“å­˜
    result: OnceCell<Result<T, DynError>>,
    /// ç­‰å¾…è€…åˆ—è¡¨
    waiters: Mutex<Vec<Arc<Notify>>>,
}

impl<T: Send + 'static> Async<T> {
    /// åˆ›å»ºæ–°çš„ Async å€¼
    pub fn new<F>(future: F) -> Self
    where
        F: Future<Output = Result<T, DynError>> + Send + 'static,
    {
        let inner = Arc::new(AsyncInner {
            future: Mutex::new(Some(Box::pin(future))),
            executor: TaskExecutor::new(),
            state: AtomicU8::new(AsyncState::Pending as u8),
            result: OnceCell::new(),
            waiters: Mutex::new(Vec::new()),
        });

        Self { inner }
    }

    /// æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
    pub fn is_ready(&self) -> bool {
        matches!(
            AsyncState::from_u8(self.inner.state.load(Ordering::SeqCst)),
            AsyncState::Completed(_)
        )
    }

    /// è·å–ç»“æœï¼ˆåŒæ­¥é˜»å¡ï¼‰
    pub fn get(&self) -> Result<&T, &DynError> {
        loop {
            match AsyncState::from_u8(self.inner.state.load(Ordering::SeqCst)) {
                AsyncState::Pending => {
                    // å°è¯•æ‰§è¡Œ
                    self.inner.executor.try_execute();
                    // è‡ªæ—‹ç­‰å¾…
                    std::hint::spin_loop();
                }
                AsyncState::Running => {
                    std::hint::spin_loop();
                }
                AsyncState::Completed => {
                    return self.inner.result.get().unwrap().as_ref();
                }
            }
        }
    }
}

/// å¼‚æ­¥çŠ¶æ€
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum AsyncState {
    Pending = 0,
    Running = 1,
    Completed = 2,
    Failed = 3,
}

/// è‡ªåŠ¨è§£åŒ…å®ç°
impl<T: Send + 'static> std::ops::Deref for Async<T> {
    type Target = T;

    fn deref(&self) -> &T {
        // é˜»å¡ç­‰å¾…å¹¶è¿”å›å¼•ç”¨
        self.get().expect("Async value failed")
    }
}
```

### 3.9 libuv IO è°ƒåº¦å¼•æ“

```rust
// src/runtime/io/mod.rs

/// libuv IO è°ƒåº¦å™¨ - å·¥ä¸šçº§å¼‚æ­¥ IO å¼•æ“
///
/// ä½¿ç”¨ libuv ä½œä¸ºåº•å±‚ IO å¼•æ“ï¼Œæä¾›ï¼š
/// - é«˜æ€§èƒ½å¼‚æ­¥ IOï¼ˆepoll/kqueue/IOCPï¼‰
/// - TCP/UDP ç½‘ç»œæ“ä½œ
/// - æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
/// - å®šæ—¶å™¨å’Œä¿¡å·å¤„ç†
///
/// ä¾èµ–: uv-rs (Rust libuv ç»‘å®š)
#[derive(Debug)]
pub struct UvIOScheduler {
    /// libuv äº‹ä»¶å¾ªç¯
    loop: Arc<uv_loop::UvLoop>,
    /// è¿è¡ŒçŠ¶æ€
    running: Arc<AtomicBool>,
    /// IO å®Œæˆå›è°ƒ
    callbacks: Arc<RwLock<HashMap<usize, Box<dyn FnOnce() + Send>>>>,
    /// ä¸‹ä¸€ä¸ªå›è°ƒ ID
    next_callback_id: AtomicUsize,
}

impl UvIOScheduler {
    /// åˆ›å»ºæ–°çš„ libuv IO è°ƒåº¦å™¨
    pub fn new() -> Result<Self, UvError> {
        let loop_raw = unsafe { uv_sys::uv_loop_new() };
        if loop_raw.is_null() {
            return Err(UvError::AllocationFailed);
        }

        let loop_ = Arc::new(uv_loop::UvLoop::from_raw(loop_raw));

        Ok(Self {
            loop: loop_,
            running: Arc::new(AtomicBool::new(true)),
            callbacks: Arc::new(RwLock::new(HashMap::new())),
            next_callback_id: AtomicUsize::new(0),
        })
    }

    /// è·å–äº‹ä»¶å¾ªç¯å¼•ç”¨
    pub fn loop(&self) -> &Arc<uv_loop::UvLoop> {
        &self.loop
    }

    /// è¿è¡Œäº‹ä»¶å¾ªç¯
    pub fn run(&self) -> Result<(), UvError> {
        self.running.store(true, Ordering::SeqCst);

        while self.running.load(Ordering::SeqCst) {
            // è¿è¡Œ libuv äº‹ä»¶å¾ªç¯
            // é˜»å¡ç›´åˆ°æœ‰äº‹ä»¶å‘ç”Ÿæˆ–è¶…æ—¶
            unsafe {
                uv_sys::uv_run(
                    self.loop.as_ptr(),
                    uv_sys::UV_RUN_DEFAULT,
                );
            }
        }

        Ok(())
    }

    /// åœæ­¢äº‹ä»¶å¾ªç¯
    pub fn stop(&self) {
        self.running.store(false, Ordering::SeqCst);
        unsafe {
            uv_sys::uv_stop(self.loop.as_ptr());
        }
    }

    /// æ³¨å†Œ TCP è¯»å–æ“ä½œ
    pub fn tcp_read(
        &self,
        stream: &mut UvTcpStream,
        buf: &mut [u8],
    ) -> Result<usize, UvError> {
        let (sender, receiver) = oneshot::channel();

        // è®¾ç½®è¯»å–å›è°ƒ
        stream.set_read_callback(move |result| {
            let _ = sender.send(result);
        });

        // å¼€å§‹å¼‚æ­¥è¯»å–
        unsafe {
            uv_sys::uv_read_start(
                stream.as_ptr() as *mut uv_sys::uv_stream_t,
                Some(read_alloc_callback),
                Some(read_callback) as _,
            );
        }

        // ç­‰å¾…ç»“æœ
        receiver.recv_timeout(Duration::from_secs(30))
            .map_err(|_| UvError::Timeout)?
    }

    /// å¼‚æ­¥ TCP è¿æ¥
    pub fn tcp_connect(
        &self,
        addr: &SocketAddr,
    ) -> Result<UvTcpStream, UvError> {
        let mut stream = UvTcpStream::new()?;
        let connect_req = unsafe { uv_sys::uv_connect_t_new() };

        // è®¾ç½®è¿æ¥å›è°ƒ
        let (sender, receiver) = oneshot::channel::<Result<(), UvError>>();

        // å‘èµ·è¿æ¥
        unsafe {
            uv_sys::uv_tcp_connect(
                connect_req,
                stream.as_ptr(),
                addr.as_ptr() as *const sockaddr,
                Some(connect_callback) as _,
            );
        }

        // ç­‰å¾…è¿æ¥å®Œæˆ
        receiver.recv_timeout(Duration::from_secs(30))
            .map_err(|_| UvError::Timeout)??;

        Ok(stream)
    }

    /// å¼‚æ­¥æ–‡ä»¶è¯»å–
    pub fn fs_read(
        &self,
        file: &mut UvFsFile,
        buf: &mut [u8],
        offset: i64,
    ) -> Result<usize, UvError> {
        let (sender, receiver) = oneshot::channel();

        // è®¾ç½®æ–‡ä»¶ç³»ç»Ÿå›è°ƒ
        let req = unsafe { uv_sys::uv_fs_t_new() };

        unsafe {
            uv_sys::uv_fs_read(
                self.loop.as_ptr(),
                req,
                file.fd(),
                buf.as_mut_ptr() as *mut i8,
                buf.len() as i64,
                offset,
                Some(fs_callback) as _,
            );
        }

        receiver.recv_timeout(Duration::from_secs(60))
            .map_err(|_| UvError::Timeout)?
    }

    /// åˆ›å»ºå®šæ—¶å™¨
    pub fn create_timer(&self, timeout: u64, repeat: u64) -> Result<UvTimer, UvError> {
        UvTimer::new(&self.loop, timeout, repeat)
    }
}

/// TCP æµå°è£…
#[derive(Debug)]
pub struct UvTcpStream {
    /// åº•å±‚ uv_tcp_t å¥æŸ„
    handle: *mut uv_sys::uv_tcp_t,
    /// è¯»å›è°ƒ
    read_cb: Mutex<Option<Box<dyn FnMut(Result<usize, UvError>)>>>,
    /// å…³é—­çŠ¶æ€
    closed: AtomicBool,
}

impl UvTcpStream {
    /// åˆ›å»ºæ–°çš„ TCP æµ
    pub fn new() -> Result<Self, UvError> {
        let handle = unsafe { uv_sys::uv_tcp_t_new() };
        if handle.is_null() {
            return Err(UvError::AllocationFailed);
        }

        Ok(Self {
            handle,
            read_cb: Mutex::new(None),
            closed: AtomicBool::new(false),
        })
    }

    /// åˆå§‹åŒ– TCP æµï¼ˆéœ€åœ¨äº‹ä»¶å¾ªç¯ä¸­è°ƒç”¨ï¼‰
    pub fn init(&mut self, loop_: &uv_loop::UvLoop) -> Result<(), UvError> {
        let ret = unsafe {
            uv_sys::uv_tcp_init(loop_.as_ptr(), self.handle)
        };
        if ret < 0 {
            Err(UvError::from_raw(ret))
        } else {
            Ok(())
        }
    }

    /// ç»‘å®šåˆ°åœ°å€
    pub fn bind(&mut self, addr: &SocketAddr) -> Result<(), UvError> {
        let ret = unsafe {
            uv_sys::uv_tcp_bind(
                self.handle,
                addr.as_ptr() as *const sockaddr,
                0,
            )
        };
        if ret < 0 {
            Err(UvError::from_raw(ret))
        } else {
            Ok(())
        }
    }

    /// è®¾ç½®è¯»å›è°ƒ
    fn set_read_callback<F>(&mut self, cb: F)
    where
        F: FnMut(Result<usize, UvError>) + 'static,
    {
        *self.read_cb.lock().unwrap() = Some(Box::new(cb));
    }

    /// è·å–åº•å±‚å¥æŸ„æŒ‡é’ˆ
    fn as_ptr(&self) -> *mut uv_sys::uv_tcp_t {
        self.handle
    }
}

/// å®šæ—¶å™¨å°è£…
#[derive(Debug)]
pub struct UvTimer {
    /// åº•å±‚ uv_timer_t å¥æŸ„
    handle: *mut uv_sys::uv_timer_t,
    /// å›è°ƒ
    callback: Mutex<Option<Box<dyn FnMut() + Send>>>,
}

impl UvTimer {
    /// åˆ›å»ºæ–°å®šæ—¶å™¨
    pub fn new(loop_: &uv_loop::UvLoop, timeout: u64, repeat: u64) -> Result<Self, UvError> {
        let handle = unsafe { uv_sys::uv_timer_t_new() };
        if handle.is_null() {
            return Err(UvError::AllocationFailed);
        }

        let timer = Self {
            handle,
            callback: Mutex::new(None),
        };

        unsafe {
            uv_sys::uv_timer_init(loop_.as_ptr(), handle);
        }

        Ok(timer)
    }

    /// å¯åŠ¨å®šæ—¶å™¨
    pub fn start<F>(&mut self, timeout: u64, repeat: u64, cb: F)
    where
        F: FnMut() + 'static,
    {
        *self.callback.lock().unwrap() = Some(Box::new(cb));

        unsafe {
            uv_sys::uv_timer_start(
                self.handle,
                Some(timer_callback),
                timeout,
                repeat,
            );
        }
    }

    /// åœæ­¢å®šæ—¶å™¨
    pub fn stop(&mut self) {
        unsafe {
            uv_sys::uv_timer_stop(self.handle);
        }
    }

    /// è·å–åº•å±‚å¥æŸ„æŒ‡é’ˆ
    fn as_ptr(&self) -> *mut uv_sys::uv_timer_t {
        self.handle
    }
}

/// æ–‡ä»¶ç³»ç»Ÿæ“ä½œå°è£…
#[derive(Debug)]
pub struct UvFsFile {
    /// åº•å±‚ uv_fs_t å¥æŸ„
    file: i32,
}

impl UvFsFile {
    /// æ‰“å¼€æ–‡ä»¶
    pub fn open(path: &str, flags: i32, mode: i32) -> Result<Self, UvError> {
        let req = unsafe { uv_sys::uv_fs_t_new() };

        let ret = unsafe {
            uv_sys::uv_fs_open(
                ptr::null_mut(),
                req,
                path.as_ptr() as *const i8,
                flags,
                mode,
                None,
            )
        };

        if ret < 0 {
            Err(UvError::from_raw(ret))
        } else {
            Ok(Self { file: ret })
        }
    }

    /// å…³é—­æ–‡ä»¶
    pub fn close(&self) -> Result<(), UvError> {
        let req = unsafe { uv_sys::uv_fs_t_new() };

        let ret = unsafe {
            uv_sys::uv_fs_close(ptr::null_mut(), req, self.file, None)
        };

        if ret < 0 {
            Err(UvError::from_raw(ret))
        } else {
            Ok(())
        }
    }

    /// è·å–æ–‡ä»¶æè¿°ç¬¦
    fn fd(&self) -> i32 {
        self.file
    }
}
```

### 3.10 IO è°ƒåº¦å™¨ä¸ FlowScheduler é›†æˆ

```rust
// FlowScheduler ä¸­çš„ IO é›†æˆ

impl FlowScheduler {
    /// åˆ›å»ºå¸¦ libuv IO çš„è°ƒåº¦å™¨
    pub fn new_with_io() -> Result<Self, UvError> {
        let io_scheduler = UvIOScheduler::new()?;

        let config = SchedulerConfig {
            num_workers: num_cpus::get(),
            use_libuv_io: true,
            ..Default::default()
        };

        let mut scheduler = Self::with_config(config);
        scheduler.io_scheduler = Some(io_scheduler);

        Ok(scheduler)
    }

    /// æäº¤ IO ä»»åŠ¡
    pub fn submit_io_task<F, T>(&self, task: F) -> Async<T>
    where
        F: FnOnce() -> Result<T, UvError> + Send + 'static,
        T: Send + 'static,
    {
        let (sender, receiver) = oneshot::channel();

        // åœ¨ IO çº¿ç¨‹ä¸­æ‰§è¡Œ
        let io_scheduler = self.io_scheduler.as_ref().unwrap();
        let thread_pool = self.blocking_pool.clone();

        thread_pool.execute(move || {
            let result = task();
            let _ = sender.send(result);
        });

        // è¿”å› Async å€¼
        Async::new(async {
            receiver.recv()
                .map_err(|_| DynError::from("IO task channel closed"))?
        })
    }
}
```

---

## å››ã€æ±‚å€¼ç­–ç•¥è®¾è®¡

### 4.1 é»˜è®¤è¡Œä¸ºï¼šæƒ°æ€§æ±‚å€¼

```yaoxiang
# è„šæœ¬å¤´é…ç½®å¹¶è¡Œæ ¸å¿ƒæ•°
# @cores: 4

# æ‰€æœ‰å‡½æ•°é»˜è®¤æƒ°æ€§æ±‚å€¼
fn heavy_computation(x: Int) -> Int = (x) => {
    # è¿™ä¸ªå‡½æ•°ä¸ä¼šç«‹å³æ‰§è¡Œ
    # åªæœ‰å½“ç»“æœè¢«ä½¿ç”¨æ—¶æ‰æ‰§è¡Œ
    fibonacci(x)
}

fn main() -> Void = () => {
    # heavy_computation è¿”å› Intï¼Œç±»å‹æ˜¯ Lazy[Int]
    result = heavy_computation(100)

    # åœ¨è¿™é‡Œï¼Œresult è¢«ç”¨äºåŠ æ³•ï¼Œè§¦å‘æ±‚å€¼
    # ç³»ç»Ÿè‡ªåŠ¨æ‰¾åˆ°æœ€ä½³æ—¶æœºå¹¶è¡Œæ‰§è¡Œ
    total = result + heavy_computation(200)
}
```

### 4.2 æ€¥åˆ‡æ±‚å€¼æ³¨è§£

```yaoxiang
# å¼ºåˆ¶æ€¥åˆ‡æ±‚å€¼
@eager fn log_message(msg: String) -> Void = (msg) => {
    print(msg)
}

# å¼ºåˆ¶æƒ°æ€§ï¼ˆæ˜¾å¼ï¼Œå¯çœç•¥ï¼‰
@lazy fn optional_step(x: Int) -> Int = (x) => {
    x * 2
}
```

### 4.3 spawn ç²¾ç»†æ§åˆ¶

```yaoxiang
fn fetch_data(url: String) -> JSON = (url) => { ... }
fn parse(json: JSON) -> Model = (json) => { ... }

fn main() -> Void = () => {
    # æ˜¾å¼å¹¶è¡Œå—
    let (data1, data2) = spawn {
        parse(fetch_data("url1")),
        parse(fetch_data("url2"))
    }

    # æ•°æ®å¹¶è¡Œ
    let results = spawn for item in items {
        process(item)
    }

    # å•ä¸ªæ˜¾å¼å¼‚æ­¥å‡½æ•°
    let data = spawn fetch_data("url")
}
```

### 4.4 å‰¯ä½œç”¨å¤„ç†ï¼ˆ@effectï¼‰

```yaoxiang
# å‰¯ä½œç”¨å‡½æ•°å¿…é¡»æ ‡æ³¨ @effect
@effect fn log_to_file(path: String, msg: String) -> Void = (path, msg) => {
    std::fs.append(path, msg)
}

# é»˜è®¤ç«‹å³æ‰§è¡Œ
fn main() -> Void = () => {
    log_to_file("log.txt", "start")  # ç«‹å³æ‰§è¡Œ
}

# å»¶è¿Ÿåˆ°ä½œç”¨åŸŸç»“æŸ
@effect(timing: ScopeEnd) fn cleanup() -> Void = () => {
    print("cleanup at scope end")
}

fn main() -> Void = () => {
    {
        cleanup()  # ä½œç”¨åŸŸç»“æŸæ—¶æ‰§è¡Œ
        # ...
    }  # è¿™é‡Œè§¦å‘ cleanup
}
```

### 4.5 è‡ªåŠ¨æ£€æµ‹æœ€ä½³ç­–ç•¥

```rust
// è°ƒåº¦å™¨è‡ªåŠ¨åˆ†æå¹¶é€‰æ‹©æœ€ä¼˜ç­–ç•¥
impl FlowScheduler {
    /// åˆ†æå¹¶é€‰æ‹©æœ€ä½³æ±‚å€¼ç­–ç•¥
    fn analyze_evaluation_strategy(&self, node: &DAGNode) -> EvaluationStrategy {
        match &node.kind {
            NodeKind::LazyCompute => {
                // æ£€æŸ¥ä¾èµ–å…³ç³»å’Œå°±ç»ªèŠ‚ç‚¹æ•°
                if self.estimate_parallelism(node) > self.config.parallel_threshold {
                    EvaluationStrategy::Parallel
                } else {
                    EvaluationStrategy::Sequential
                }
            }
            NodeKind::EagerCompute => {
                EvaluationStrategy::Immediate
            }
            NodeKind::ParallelBlock => {
                EvaluationStrategy::AggressiveParallel
            }
            _ => EvaluationStrategy::Default,
        }
    }
}
```

---

## äº”ã€æµ‹è¯•è®¡åˆ’

### 5.1 DAG æ¨¡å—æµ‹è¯•

```rust
// src/runtime/dag/tests/mod.rs

#[cfg(test)]
mod node_tests {
    use super::*;

    #[test]
    fn test_node_creation() {
        let node = DAGNode::new(NodeId(0), NodeKind::Compute);
        assert_eq!(node.state(), NodeState::Pending);
        assert!(node.is_ready());
    }

    #[test]
    fn test_node_dependencies() {
        let mut node = DAGNode::new(NodeId(0), NodeKind::Compute);
        node.add_parent(NodeId(1));
        node.add_parent(NodeId(2));
        assert!(!node.is_ready());

        node.parent_completed();
        assert!(!node.is_ready());

        node.parent_completed();
        assert!(node.is_ready());
    }

    #[test]
    fn test_node_state_transitions() {
        let node = DAGNode::new(NodeId(0), NodeKind::Compute);
        assert_eq!(node.state(), NodeState::Pending);

        node.set_state(NodeState::Scheduled);
        assert_eq!(node.state(), NodeState::Scheduled);

        node.set_state(NodeState::Running);
        assert_eq!(node.state(), NodeState::Running);

        node.set_state(NodeState::Completed);
        assert_eq!(node.state(), NodeState::Completed);
    }

    #[test]
    fn test_node_thread_safety() {
        use std::sync::{Arc, Barrier};
        use std::thread;

        let node = Arc::new(DAGNode::new(NodeId(0), NodeKind::Compute));
        let barrier = Arc::new(Barrier::new(10));

        let handles: Vec<_> = (0..10)
            .map(|_| {
                let node = node.clone();
                let barrier = barrier.clone();
                thread::spawn(move || {
                    barrier.wait();
                    for _ in 0..1000 {
                        node.set_state(NodeState::Running);
                        node.set_state(NodeState::Pending);
                    }
                })
            })
            .collect();

        for handle in handles {
            handle.join().unwrap();
        }

        // æœ€ç»ˆçŠ¶æ€åº”è¯¥æ˜¯ Pending æˆ– Scheduled æˆ– Running
        // ä½†ä¸åº”è¯¥æ˜¯ Completedï¼ˆå› ä¸ºæ²¡æœ‰çœŸæ­£å®Œæˆï¼‰
    }
}

#[cfg(test)]
mod graph_tests {
    use super::*;

    #[test]
    fn test_graph_add_node() {
        let graph = ComputationDAG::new();
        let node_id = graph.add_node(NodeKind::Compute, &[]);
        assert_eq!(node_id.inner(), 0);
    }

    #[test]
    fn test_graph_dependencies() {
        let graph = ComputationDAG::new();

        // A -> B -> C
        let id_a = graph.add_node(NodeKind::Compute, &[]);
        let id_b = graph.add_node(NodeKind::Compute, &[id_a]);
        let id_c = graph.add_node(NodeKind::Compute, &[id_b]);

        // A åº”è¯¥ç«‹å³å°±ç»ª
        assert!(graph.pop_ready().is_some());

        // B å’Œ C ä¸åº”è¯¥å°±ç»ª
        assert!(graph.pop_ready().is_none());
    }

    #[test]
    fn test_graph_completion() {
        let graph = ComputationDAG::new();

        let id_a = graph.add_node(NodeKind::Compute, &[]);
        let id_b = graph.add_node(NodeKind::Compute, &[id_a]);

        // å®Œæˆ A
        graph.node_completed(id_a);

        // B åº”è¯¥å°±ç»ª
        assert!(graph.pop_ready().is_some());

        // å®Œæˆ B
        graph.node_completed(id_b);

        // æ²¡æœ‰æ›´å¤šå°±ç»ªèŠ‚ç‚¹
        assert!(graph.pop_ready().is_none());
    }

    #[test]
    fn test_graph_parallel_execution() {
        let graph = ComputationDAG::new();

        // A å’Œ B æ— ä¾èµ–ï¼Œå¯ä»¥å¹¶è¡Œæ‰§è¡Œ
        let id_a = graph.add_node(NodeKind::Compute, &[]);
        let id_b = graph.add_node(NodeKind::Compute, &[]);

        // ä¸¤ä¸ªéƒ½åº”è¯¥å°±ç»ª
        assert_eq!(graph.pop_ready().map(|id| id.inner()), Some(id_a.inner()));
        assert_eq!(graph.pop_ready().map(|id| id.inner()), Some(id_b.inner()));

        // å®Œæˆ A å’Œ B
        graph.node_completed(id_a);
        graph.node_completed(id_b);

        assert!(graph.pop_ready().is_none());
    }

    #[test]
    fn test_graph_complex_dependencies() {
        let graph = ComputationDAG::new();

        //     A
        //    / \
        //   B   C
        //    \ /
        //     D

        let id_a = graph.add_node(NodeKind::Compute, &[]);
        let id_b = graph.add_node(NodeKind::Compute, &[id_a]);
        let id_c = graph.add_node(NodeKind::Compute, &[id_a]);
        let id_d = graph.add_node(NodeKind::Compute, &[id_b, id_c]);

        // åªæœ‰ A åº”è¯¥å°±ç»ª
        assert_eq!(graph.pop_ready().map(|id| id.inner()), Some(id_a.inner()));

        // å®Œæˆ A
        graph.node_completed(id_a);

        // B å’Œ C åº”è¯¥å°±ç»ª
        let mut ready_nodes: Vec<_> = std::iter::from_fn(|| graph.pop_ready()).collect();
        assert_eq!(ready_nodes.len(), 2);

        // å®Œæˆ B å’Œ C
        for id in ready_nodes {
            graph.node_completed(id);
        }

        // D åº”è¯¥å°±ç»ª
        assert!(graph.pop_ready().is_some());
    }
}
```

### 4.2 è°ƒåº¦å™¨æµ‹è¯•

```rust
// src/runtime/scheduler/tests/mod.rs

#[cfg(test)]
mod work_stealer_tests {
    use super::*;

    #[test]
    fn test_work_stealer_creation() {
        let stealer = WorkStealer::new(4);
        // åº”è¯¥èƒ½æ­£å¸¸åˆ›å»º
    }

    #[test]
    fn test_work_stealer_steal_random() {
        let stealer = WorkStealer::new(4);
        // ç©ºé˜Ÿåˆ—åº”è¯¥è¿”å› None
        assert!(stealer.steal_random().is_none());
    }

    #[test]
    fn test_work_stealer_parallel() {
        use std::sync::{Arc, Barrier};
        use std::thread;

        let stealer = Arc::new(WorkStealer::new(4));
        let barrier = Arc::new(Barrier::new(4));

        let handles: Vec<_> = (0..4)
            .map(|_| {
                let stealer = stealer.clone();
                let barrier = barrier.clone();
                thread::spawn(move || {
                    barrier.wait();
                    for _ in 0..100 {
                        stealer.steal_random();
                    }
                })
            })
            .collect();

        for handle in handles {
            handle.join().unwrap();
        }
    }
}

#[cfg(test)]
mod flow_scheduler_tests {
    use super::*;

    #[test]
    fn test_scheduler_creation() {
        let scheduler = FlowScheduler::new();
        // åº”è¯¥èƒ½æ­£å¸¸åˆ›å»º
    }

    #[test]
    fn test_scheduler_spawn_untracked() {
        let scheduler = FlowScheduler::new();
        let task = Arc::new(Task::new(TaskId(0), TaskPriority::Normal, 1024));
        scheduler.spawn_untracked(task);
    }

    #[test]
    fn test_scheduler_parallel_tasks() {
        use std::sync::atomic::{AtomicUsize, Ordering};
        use std::sync::{Arc, Barrier};

        let scheduler = Arc::new(FlowScheduler::new());
        let counter = Arc::new(AtomicUsize::new(0));
        let barrier = Arc::new(Barrier::new(4));
        let mut handles = Vec::new();

        for i in 0..4 {
            let scheduler = scheduler.clone();
            let counter = counter.clone();
            let barrier = barrier.clone();

            let handle = thread::spawn(move || {
                barrier.wait();
                let task = Arc::new(Task::new(TaskId(i), TaskPriority::Normal, 1024));
                scheduler.spawn_untracked(task);

                counter.fetch_add(1, Ordering::SeqCst);
            });
            handles.push(handle);
        }

        for handle in handles {
            handle.join().unwrap();
        }

        assert_eq!(counter.load(Ordering::SeqCst), 4);
    }

    #[test]
    fn test_scheduler_blocking_pool() {
        // æµ‹è¯•é˜»å¡æ“ä½œè¢«æ­£ç¡®éš”ç¦»
    }

    #[test]
    fn test_scheduler_stress() {
        use std::sync::atomic::{AtomicUsize, Ordering};
        use std::sync::{Arc, Barrier};

        let scheduler = Arc::new(FlowScheduler::new());
        let counter = Arc::new(AtomicUsize::new(0));
        let barrier = Arc::new(Barrier::new(10));
        let mut handles = Vec::new();

        for i in 0..100 {
            let scheduler = scheduler.clone();
            let counter = counter.clone();
            let barrier = barrier.clone();

            let handle = thread::spawn(move || {
                barrier.wait();
                let task = Arc::new(Task::new(TaskId(i), TaskPriority::Normal, 1024));
                scheduler.spawn_untracked(task);

                counter.fetch_add(1, Ordering::SeqCst);
            });
            handles.push(handle);
        }

        for handle in handles {
            handle.join().unwrap();
        }

        assert_eq!(counter.load(Ordering::SeqCst), 100);
    }
}
```

### 5.3 æƒ°æ€§æ±‚å€¼æµ‹è¯•

```rust
// src/runtime/dag/tests/lazy_eval.rs

#[cfg(test)]
mod lazy_evaluation_tests {
    use super::*;

    #[test]
    fn test_lazy_node_not_executed_until_needed() {
        let graph = ComputationDAG::new();
        let counter = Arc::new(AtomicUsize::new(0));

        // åˆ›å»ºæƒ°æ€§èŠ‚ç‚¹
        let node_id = graph.add_node(
            NodeKind::LazyCompute,
            &[],
        );

        // èŠ‚ç‚¹å·²å°±ç»ªä½†å°šæœªæ‰§è¡Œ
        assert!(graph.pop_ready().is_some());

        // èŠ‚ç‚¹ä¸åº”è¯¥è¢«è®¡æ•°ï¼ˆè¿˜æ²¡çœŸæ­£æ‰§è¡Œï¼‰
        assert_eq!(counter.load(Ordering::SeqCst), 0);
    }

    #[test]
    fn test_lazy_node_executed_on_access() {
        let graph = ComputationDAG::new();
        let counter = Arc::new(AtomicUsize::new(0));

        let node_id = graph.add_node(NodeKind::LazyCompute, &[]);

        // è·å–å°±ç»ªèŠ‚ç‚¹
        let ready_id = graph.pop_ready().unwrap();
        assert_eq!(ready_id, node_id);

        // æ¨¡æ‹Ÿè®¿é—®ç»“æœ
        graph.node_completed(node_id);

        // èŠ‚ç‚¹å®Œæˆ
        assert!(graph.pop_ready().is_none());
    }

    #[test]
    fn test_lazy_chain_execution() {
        // A -> B -> Cï¼ˆæƒ°æ€§é“¾ï¼‰
        let graph = ComputationDAG::new();

        let id_a = graph.add_node(NodeKind::LazyCompute, &[]);
        let id_b = graph.add_node(NodeKind::LazyCompute, &[id_a]);
        let id_c = graph.add_node(NodeKind::LazyCompute, &[id_b]);

        // åªæœ‰ A å°±ç»ª
        assert_eq!(graph.pop_ready().map(|id| id.inner()), Some(id_a.inner()));

        // å®Œæˆ A å B å°±ç»ª
        graph.node_completed(id_a);
        assert_eq!(graph.pop_ready().map(|id| id.inner()), Some(id_b.inner()));

        // å®Œæˆ B å C å°±ç»ª
        graph.node_completed(id_b);
        assert_eq!(graph.pop_ready().map(|id| id.inner()), Some(id_c.inner()));
    }

    #[test]
    fn test_eager_vs_lazy_behavior() {
        // æ€¥åˆ‡èŠ‚ç‚¹åº”è¯¥ç«‹å³æ‰§è¡Œ
        let graph = ComputationDAG::new();
        let exec_order = Arc::new(Mutex::new(Vec::new()));

        let eager_id = graph.add_node(NodeKind::EagerCompute, &[]);
        let lazy_id = graph.add_node(NodeKind::LazyCompute, &[]);

        // æ€¥åˆ‡èŠ‚ç‚¹åº”è¯¥å·²å°±ç»ª
        assert!(graph.pop_ready().is_some());

        // æƒ°æ€§èŠ‚ç‚¹å¦‚æœæœ‰ä¾èµ–ä¹Ÿåº”è¯¥å°±ç»ª
        assert!(graph.pop_ready().is_some());
    }
}

#[cfg(test)]
mod spawn_tests {
    use super::*;

    #[test]
    fn test_parallel_block_nodes() {
        let graph = ComputationDAG::new();

        // spawn { a, b } åˆ›å»ºå¹¶è¡Œå—
        let block_id = graph.add_node(
            NodeKind::ParallelBlock {
                exprs: vec![],
                barrier: true,
            },
            &[],
        );

        // å¹¶è¡Œå—å†…çš„èŠ‚ç‚¹åº”è¯¥å¯ä»¥å¹¶è¡Œæ‰§è¡Œ
        let id_a = graph.add_node(NodeKind::Compute, &[]);
        let id_b = graph.add_node(NodeKind::Compute, &[]);

        // ä¸¤ä¸ªæ— ä¾èµ–èŠ‚ç‚¹åº”è¯¥åŒæ—¶å°±ç»ª
        let mut ready = Vec::new();
        while let Some(id) = graph.pop_ready() {
            ready.push(id);
        }
        assert_eq!(ready.len(), 2);
    }

    #[test]
    fn test_data_parallel_nodes() {
        let graph = ComputationDAG::new();

        // spawn for x in xs åˆ›å»ºæ•°æ®å¹¶è¡Œ
        let dp_id = graph.add_node(
            NodeKind::DataParallel {
                var: "x".to_string(),
                iter: Expr::List(vec![]),
                body: Expr::Int(0),
            },
            &[],
        );

        // æ•°æ®å¹¶è¡ŒèŠ‚ç‚¹åº”è¯¥å°±ç»ª
        assert!(graph.pop_ready().is_some());
    }

    #[test]
    fn test_effect_nodes() {
        let graph = ComputationDAG::new();

        // @effect å‰¯ä½œç”¨èŠ‚ç‚¹
        let effect_id = graph.add_node(
            NodeKind::Effect {
                func: Expr::Lambda(vec![], Box::new(Expr::Int(0))),
                timing: EffectTiming::Immediate,
            },
            &[],
        );

        // å‰¯ä½œç”¨èŠ‚ç‚¹åº”è¯¥ç«‹å³æ‰§è¡Œ
        assert!(graph.pop_ready().is_some());
    }
}
```

### 5.4 å·¥ä½œçªƒå–æµ‹è¯•

```rust
#[cfg(test)]
mod work_stealing_tests {
    use super::*;

    #[test]
    fn test_work_stealer_distribution() {
        use std::sync::atomic::{AtomicUsize, Ordering};
        use std::sync::{Arc, Barrier};
        use std::thread;

        let stealer = Arc::new(WorkStealer::new(4));
        let distribution = Arc::new(Mutex::new(vec![0usize; 4]));
        let barrier = Arc::new(Barrier::new(4));

        let handles: Vec<_> = (0..4)
            .map(|worker_id| {
                let stealer = stealer.clone();
                let distribution = distribution.clone();
                let barrier = barrier.clone();
                thread::spawn(move || {
                    barrier.wait();
                    for _ in 0..100 {
                        if let Some(task) = stealer.steal_random() {
                            let mut dist = distribution.lock().unwrap();
                            dist[worker_id] += 1;
                        }
                    }
                })
            })
            .collect();

        for handle in handles {
            handle.join().unwrap();
        }

        // éªŒè¯ä»»åŠ¡åˆ†å¸ƒç›¸å¯¹å‡åŒ€
        let dist = distribution.lock().unwrap();
        let max = *dist.iter().max().unwrap();
        let min = *dist.iter().min().unwrap();
        assert!(max - min < 50); // å…è®¸ä¸€å®šçš„ä¸å‡åŒ€
    }

    #[test]
    fn test_work_stealer_concurrent_access() {
        use std::sync::{Arc, Barrier};
        use std::thread;

        let stealer = Arc::new(WorkStealer::new(8));
        let barrier = Arc::new(Barrier::new(8));

        let handles: Vec<_> = (0..8)
            .map(|_| {
                let stealer = stealer.clone();
                let barrier = barrier.clone();
                thread::spawn(move || {
                    barrier.wait();
                    for _ in 0..1000 {
                        stealer.steal_random();
                    }
                })
            })
            .collect();

        for handle in handles {
            handle.join().unwrap();
        }
        // æ²¡æœ‰ panic å°±æ˜¯æˆåŠŸ
    }
}
```

### 5.5 é›†æˆæµ‹è¯•

```rust
#[cfg(test)]
mod integration_tests {
    use super::*;

    #[test]
    fn test_full_parallel_execution() {
        use std::sync::atomic::{AtomicUsize, Ordering};
        use std::sync::{Arc, Barrier};
        use std::thread;
        use std::time::Duration;

        let scheduler = Arc::new(FlowScheduler::new());
        let start_time = Arc::new(Mutex::new(std::time::Instant::now()));
        let counter = Arc::new(AtomicUsize::new(0));
        let barrier = Arc::new(Barrier::new(8));

        let handles: Vec<_> = (0..8)
            .map(|i| {
                let scheduler = scheduler.clone();
                let start_time = start_time.clone();
                let counter = counter.clone();
                let barrier = barrier.clone();
                thread::spawn(move || {
                    barrier.wait();
                    let local_start = *start_time.lock().unwrap();

                    // æ¨¡æ‹Ÿ CPU å¯†é›†å‹ä»»åŠ¡
                    let _ = (0..1000000).fold(0, |acc, x| acc ^ x);

                    let elapsed = local_start.elapsed().as_millis();
                    println!("Task {} finished in {}ms", i, elapsed);

                    counter.fetch_add(1, Ordering::SeqCst);
                })
            })
            .collect();

        for handle in handles {
            handle.join().unwrap();
        }

        assert_eq!(counter.load(Ordering::SeqCst), 8);
    }

    #[test]
    fn test_dag_stress_test() {
        use std::sync::atomic::{AtomicUsize, Ordering};
        use std::sync::{Arc, Barrier};

        let graph = Arc::new(ComputationDAG::new());
        let counter = Arc::new(AtomicUsize::new(0));
        let barrier = Arc::new(Barrier::new(10));

        // åˆ›å»º 1000 ä¸ªèŠ‚ç‚¹å½¢æˆå¤æ‚ DAG
        let mut handles = Vec::new();
        for _ in 0..10 {
            let graph = graph.clone();
            let counter = counter.clone();
            let barrier = barrier.clone();

            let handle = thread::spawn(move || {
                barrier.wait();
                for i in 0..100 {
                    let deps: Vec<NodeId> = (0..3)
                        .map(|_| NodeId(rand::thread_rng().gen_range(0..i.max(1))))
                        .collect();

                    graph.add_node(NodeKind::LazyCompute, &deps);
                    counter.fetch_add(1, Ordering::SeqCst);
                }
            });
            handles.push(handle);
        }

        for handle in handles {
            handle.join().unwrap();
        }

        assert_eq!(counter.load(Ordering::SeqCst), 1000);
    }

    #[test]
    fn test_async_value_concurrent_access() {
        use std::sync::Arc;
        use std::thread;

        let async_val = Arc::new(Async::new(async { Ok(42) }));

        let handles: Vec<_> = (0..100)
            .map(|_| {
                let async_val = async_val.clone();
                thread::spawn(move || {
                    let _ = &*async_val; // è‡ªåŠ¨è§£åŒ…
                })
            })
            .collect();

        for handle in handles {
            handle.join().unwrap();
        }
        // æ‰€æœ‰çº¿ç¨‹éƒ½èƒ½æ­£ç¡®è®¿é—®
    }
}
```

---

## å…­ã€å®ç°æ­¥éª¤

### é˜¶æ®µ 1ï¼šåŸºç¡€æ•°æ®ç»“æ„
1. [x] å®ç° `NodeId` å’Œ `NodeIdGenerator`
2. [x] å®ç° `DAGNode` å’Œ `DAGNodeKind`
3. [x] å®ç° `ComputationDAG`
4. [x] ç¼–å†™ DAG å•å…ƒæµ‹è¯•

### é˜¶æ®µ 2ï¼šè°ƒåº¦å™¨åŸºç¡€
1. [ ] å®ç° `TaskQueue`
2. [ ] å®ç° `WorkStealer`
3. [ ] å®ç° `FlowScheduler` éª¨æ¶
4. [ ] å®ç° `BlockingThreadPool`
5. [ ] ç¼–å†™è°ƒåº¦å™¨å•å…ƒæµ‹è¯•

### é˜¶æ®µ 3ï¼šå¼‚æ­¥å€¼ç±»å‹
1. [ ] å®ç° `AsyncState`
2. [ ] å®ç° `AsyncInner`
3. [ ] å®ç° `Async<T>`
4. [ ] å®ç°è‡ªåŠ¨è§£åŒ… (Deref)
5. [ ] ç¼–å†™ Async å•å…ƒæµ‹è¯•

### é˜¶æ®µ 4ï¼šlibuv IO è°ƒåº¦å¼•æ“ â­ æ–°å¢
1. [ ] æ·»åŠ  uv-rs ä¾èµ–åˆ° Cargo.toml
2. [ ] å®ç° `UvIOScheduler` äº‹ä»¶å¾ªç¯å°è£…
3. [ ] å®ç° `UvTcpStream` TCP æ“ä½œ
4. [ ] å®ç° `UvFsFile` æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
5. [ ] å®ç° `UvTimer` å®šæ—¶å™¨
6. [ ] ç¼–å†™ IO å•å…ƒæµ‹è¯•
7. [ ] æµ‹è¯•è·¨å¹³å°å…¼å®¹æ€§ (Linux/macOS/Windows)

### é˜¶æ®µ 5ï¼šæ±‚å€¼ç­–ç•¥
1. [ ] å®ç°æƒ°æ€§æ±‚å€¼ç­–ç•¥ `LazyCompute`
2. [ ] å®ç°æ€¥åˆ‡æ±‚å€¼ç­–ç•¥ `EagerCompute`
3. [ ] å®ç°å‰¯ä½œç”¨å¤„ç† `Effect`
4. [ ] å®ç°è‡ªåŠ¨ç­–ç•¥é€‰æ‹©
5. [ ] ç¼–å†™ç­–ç•¥æµ‹è¯•

### é˜¶æ®µ 6ï¼šspawn è¯­æ³•æ”¯æŒ
1. [ ] å®ç° `ParallelBlock` èŠ‚ç‚¹ç±»å‹
2. [ ] å®ç° `DataParallel` èŠ‚ç‚¹ç±»å‹
3. [ ] å®ç°å¹¶è¡Œå±éšœåŒæ­¥
4. [ ] ç¼–å†™ spawn æµ‹è¯•

### é˜¶æ®µ 7ï¼šé›†æˆæµ‹è¯•
1. [ ] DAG + è°ƒåº¦å™¨é›†æˆæµ‹è¯•
2. [ ] IO + è°ƒåº¦å™¨é›†æˆæµ‹è¯•
3. [ ] å¹¶å‘å‹åŠ›æµ‹è¯•
4. [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
5. [ ] å†…å­˜å®‰å…¨æµ‹è¯• (miri)

```rust
// src/runtime/async_value/tests/mod.rs

#[cfg(test)]
mod async_value_tests {
    use super::*;

    #[test]
    fn test_async_creation() {
        let async_val = Async::new(async { Ok(42) });
        assert!(!async_val.is_ready());
    }

    #[test]
    fn test_async_get() {
        let async_val = Async::new(async { Ok(42) });
        let result = async_val.get();
        assert_eq!(result.unwrap(), &42);
    }

    #[test]
    fn test_async_error() {
        let async_val = Async::new(async { Err(anyhow::anyhow!("error")) });
        let result = async_val.get();
        assert!(result.is_err());
    }

    #[test]
    fn test_async_auto_unwrap() {
        let async_val = Async::new(async { Ok(42) });
        let value: &i32 = &*async_val;
        assert_eq!(value, &42);
    }

    #[test]
    fn test_async_parallel() {
        use std::sync::Arc;
        use std::thread;

        let async_val = Arc::new(Async::new(async { Ok(42) }));

        let handles: Vec<_> = (0..10)
            .map(|_| {
                let async_val = async_val.clone();
                thread::spawn(move || {
                    let _: &i32 = &*async_val;
                })
            })
            .collect();

        for handle in handles {
            handle.join().unwrap();
        }
    }
}
```

---

## äº”ã€å®ç°æ­¥éª¤

### é˜¶æ®µ 1ï¼šåŸºç¡€æ•°æ®ç»“æ„
1. [ ] å®ç° `NodeId` å’Œ `NodeIdGenerator`
2. [ ] å®ç° `NodeState` å’Œ `NodeKind`
3. [ ] å®ç° `DAGNode`
4. [ ] å®ç° `ComputationDAG`
5. [ ] ç¼–å†™ DAG å•å…ƒæµ‹è¯•

### é˜¶æ®µ 2ï¼šè°ƒåº¦å™¨åŸºç¡€
1. [ ] å®ç° `TaskQueue`
2. [ ] å®ç° `WorkStealer`
3. [ ] å®ç° `FlowScheduler` éª¨æ¶
4. [ ] å®ç° `BlockingThreadPool`
5. [ ] ç¼–å†™è°ƒåº¦å™¨å•å…ƒæµ‹è¯•

### é˜¶æ®µ 3ï¼šå¼‚æ­¥å€¼ç±»å‹
1. [ ] å®ç° `AsyncState`
2. [ ] å®ç° `AsyncInner`
3. [ ] å®ç° `Async<T>`
4. [ ] å®ç°è‡ªåŠ¨è§£åŒ… (Deref)
5. [ ] ç¼–å†™ Async å•å…ƒæµ‹è¯•

### é˜¶æ®µ 4ï¼šé›†æˆæµ‹è¯•
1. [ ] DAG + è°ƒåº¦å™¨é›†æˆæµ‹è¯•
2. [ ] å¹¶å‘å‹åŠ›æµ‹è¯•
3. [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
4. [ ] å†…å­˜å®‰å…¨æµ‹è¯• (miri)

---

## å…­ã€libuv IO éªŒæ”¶æ ‡å‡† â­

### IO åŠŸèƒ½éªŒæ”¶
- [ ] **TCP è¿æ¥**ï¼šå¼‚æ­¥ TCP è¿æ¥æ­£å¸¸å·¥ä½œ
- [ ] **TCP è¯»å†™**ï¼šéé˜»å¡è¯»å†™æ“ä½œæ­£ç¡®æ‰§è¡Œ
- [ ] **UDP é€šä¿¡**ï¼šUDP æ•°æ®åŒ…æ”¶å‘æ­£å¸¸
- [ ] **æ–‡ä»¶ IO**ï¼šå¼‚æ­¥æ–‡ä»¶è¯»å–å’Œå†™å…¥
- [ ] **å®šæ—¶å™¨**ï¼šå®šæ—¶å›è°ƒå‡†ç¡®è§¦å‘
- [ ] **è·¨å¹³å°**ï¼šLinux/macOS/Windows å‡å¯æ­£å¸¸å·¥ä½œ

### IO æ€§èƒ½éªŒæ”¶
- [ ] **IO ååé‡**ï¼šå•è¿æ¥ > 100 MB/s
- [ ] **è¿æ¥å»ºç«‹**ï¼šTCP è¿æ¥ < 10ms (localhost)
- [ ] **å¹¶å‘è¿æ¥**ï¼šæ”¯æŒ > 10,000 å¹¶å‘è¿æ¥
- [ ] **å®šæ—¶ç²¾åº¦**ï¼šå®šæ—¶å™¨è¯¯å·® < 1ms

### IO ç¨³å®šæ€§éªŒæ”¶
- [ ] **æ— å†…å­˜æ³„æ¼**ï¼šé•¿æ—¶é—´è¿è¡Œæ— å†…å­˜å¢é•¿
- [ ] **æ— å¥æŸ„æ³„æ¼**ï¼šè¿æ¥å…³é—­åæ­£ç¡®é‡Šæ”¾èµ„æº
- [ ] **é”™è¯¯å¤„ç†**ï¼šç½‘ç»œé”™è¯¯æ­£ç¡®ä¼ æ’­
- [ ] **è¿æ¥æ¢å¤**ï¼šæ–­çº¿åèƒ½æ­£ç¡®å¤„ç†

---

## ä¸ƒã€å‘åå…¼å®¹æ€§

```rust
// src/runtime/scheduler/compat.rs

/// æ—§ç‰ˆ Scheduler APIï¼ˆå·²åºŸå¼ƒï¼‰
#[deprecated(since = "0.3.0", note = "è¯·ä½¿ç”¨ FlowScheduler")]
pub struct Scheduler {
    inner: FlowScheduler,
}

#[deprecated]
impl Scheduler {
    pub fn new() -> Self {
        Self {
            inner: FlowScheduler::new(),
        }
    }

    #[deprecated]
    pub fn spawn(&self, task: Arc<Task>) {
        self.inner.spawn_untracked(task);
    }
}

// è®©æ—§ä»£ç å¯ä»¥ç»§ç»­ç¼–è¯‘
#[deprecated]
pub fn create_scheduler() -> Scheduler {
    Scheduler::new()
}
```

---

## å…«ã€éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- [ ] **é»˜è®¤æƒ°æ€§æ±‚å€¼**ï¼šæ‰€æœ‰å‡½æ•°é»˜è®¤æƒ°æ€§ï¼Œç»“æœä½¿ç”¨æ—¶æ‰æ±‚å€¼
- [ ] **æ ¸å¿ƒæ•°é‡é…ç½®**ï¼š`// @cores: N` æ­£ç¡®é…ç½®å·¥ä½œçº¿ç¨‹æ•°
- [ ] **DAG ä¾èµ–å…³ç³»**ï¼šä¾èµ–å…³ç³»æ­£ç¡®æ„å»ºï¼Œæ— å¾ªç¯ä¾èµ–
- [ ] **ä»»åŠ¡æŒ‰ä¾èµ–æ‰§è¡Œ**ï¼šçˆ¶èŠ‚ç‚¹å®Œæˆåå­èŠ‚ç‚¹æ‰æ‰§è¡Œ
- [ ] **æ— ä¾èµ–å¹¶è¡Œ**ï¼šæ— ä¾èµ–ä»»åŠ¡å¯çœŸæ­£å¹¶è¡Œæ‰§è¡Œ
- [ ] **spawn ç²¾ç»†æ§åˆ¶**ï¼š`spawn fn`ã€`spawn {}`ã€`spawn for` æ­£ç¡®å·¥ä½œ
- [ ] **å·¥ä½œçªƒå–**ï¼šè´Ÿè½½å‡è¡¡æ­£ç¡®ï¼Œå‡å°‘é¥¥é¥¿
- [ ] **Async[T] é€æ˜**ï¼šè‡ªåŠ¨è§£åŒ…ï¼Œä½¿ç”¨æ— æ„Ÿ
- [ ] **å‰¯ä½œç”¨å¤„ç†**ï¼š`@effect` æ ‡æ³¨æ­£ç¡®æ‰§è¡Œ
- [ ] **æ··åˆæ±‚å€¼æ¨¡å¼**ï¼š`@eager`ã€`@lazy`ã€`@force` æ­£ç¡®å·¥ä½œ

### æµ‹è¯•éªŒæ”¶
- [ ] **å•å…ƒæµ‹è¯•è¦†ç›–ç‡** > 90%ï¼ˆæ¯ä¸ªå…¬å¼€ API éƒ½æœ‰æµ‹è¯•ï¼‰
- [ ] **å¹¶å‘æµ‹è¯•**ï¼šMiri æ£€æµ‹æ—  data race
- [ ] **å‹åŠ›æµ‹è¯•**ï¼š1000+ èŠ‚ç‚¹ DAG ç¨³å®šè¿è¡Œ
- [ ] **è¾¹ç•Œæµ‹è¯•**ï¼šç©ºå›¾ã€å•èŠ‚ç‚¹ã€å¤šä¾èµ–ç­‰è¾¹ç•Œæƒ…å†µ
- [ ] **çº¿ç¨‹å®‰å…¨**ï¼šå¤šçº¿ç¨‹å¹¶å‘è®¿é—®æ— ç«äº‰

### æ€§èƒ½éªŒæ”¶
- [ ] **è°ƒåº¦å»¶è¿Ÿ**ï¼šå¹³å‡ < 1ms
- [ ] **çªƒå–æˆåŠŸç‡**ï¼š> 80%
- [ ] **å†…å­˜ä½¿ç”¨**ï¼šå¯æ¥å—ï¼ˆæ— å†…å­˜æ³„æ¼ï¼‰
- [ ] **å¹¶è¡ŒåŠ é€Ÿ**ï¼šå¤šæ ¸åˆ©ç”¨ç‡ > 80%

### å‘åå…¼å®¹æ€§
- [ ] **æ—§ API å…¼å®¹**ï¼š`Scheduler` API æ ‡è®° deprecated ä½†å¯ç”¨
- [ ] **å¹³æ»‘è¿ç§»**ï¼šæ—§ä»£ç æ— éœ€ä¿®æ”¹å³å¯ç¼–è¯‘è¿è¡Œ
- [ ] **æ¥å£ç¨³å®š**ï¼šå†…éƒ¨å®ç°å¯é‡æ„ï¼Œæ¥å£ä¿æŒç¨³å®š

---

> **ä¸‹ä¸€æ­¥**ï¼šè¯·ä¸»äººæ‰¹å‡†åå¼€å§‹å®ç°
